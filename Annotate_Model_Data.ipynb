{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The path to the local git repo for Indic NLP library\n",
    "INDIC_NLP_LIB_HOME=r\"/Users/mayureshnene/Desktop/indic_nlp_library\"\n",
    "\n",
    "# The path to the local git repo for Indic NLP Resources\n",
    "INDIC_NLP_RESOURCES=r\"/Users/mayureshnene/Desktop/indic_nlp_resources\"\n",
    "\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report,plot_confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from indicnlp import common\n",
    "from indicnlp import loader\n",
    "from indicnlp.tokenize import indic_tokenize\n",
    "from indicnlp.tokenize import indic_tokenize \n",
    "from indicnlp.morph import unsupervised_morph \n",
    "from indicnlp import common\n",
    "\n",
    "sys.path.append(r'{}'.format(INDIC_NLP_LIB_HOME))\n",
    "\n",
    "common.set_resources_path(INDIC_NLP_RESOURCES)\n",
    "\n",
    "loader.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>subtask_a</th>\n",
       "      <th>subtask_b</th>\n",
       "      <th>subtask_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>राम कदम वागण्यात नाही तर बोलण्यात चुकला बीजेपी...</td>\n",
       "      <td>Offensive</td>\n",
       "      <td>TIN</td>\n",
       "      <td>GRP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>हीच का तुमची शिवसेने चि शिकवण आपली आई म्हणजे द...</td>\n",
       "      <td>Offensive</td>\n",
       "      <td>TIN</td>\n",
       "      <td>GRP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>हे वाचा गाढवांनो आणि हे ही सांगा की तुमच्या मॅ...</td>\n",
       "      <td>Offensive</td>\n",
       "      <td>TIN</td>\n",
       "      <td>GRP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>भक्त आंधळे असतात मूर्खा ना काही कळत नाही</td>\n",
       "      <td>Offensive</td>\n",
       "      <td>TIN</td>\n",
       "      <td>GRP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>१९६६ साली छत्रपती शिवाजी महाराज या जागतिक दर्ज...</td>\n",
       "      <td>Offensive</td>\n",
       "      <td>TIN</td>\n",
       "      <td>GRP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12990</th>\n",
       "      <td>पहिल्या लाटे नंतर सर्वात कमी रुग्ण\\n#कोरोना #र...</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12991</th>\n",
       "      <td>RT @DeshRat30997789: @RavindraAmbekar जगातले स...</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12992</th>\n",
       "      <td>Tata Tigor EV | देशातील सर्वात स्वस्त इलेक्ट्र...</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12993</th>\n",
       "      <td>RT @PIBMumbai: पंतप्रधान आयुष्मान भारत आरोग्यव...</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12994</th>\n",
       "      <td>@Hopeful_Addict काटकसर म्हणजे गोधड्या शिवणे.\\n...</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12995 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   tweet  subtask_a subtask_b  \\\n",
       "0      राम कदम वागण्यात नाही तर बोलण्यात चुकला बीजेपी...  Offensive       TIN   \n",
       "1      हीच का तुमची शिवसेने चि शिकवण आपली आई म्हणजे द...  Offensive       TIN   \n",
       "2      हे वाचा गाढवांनो आणि हे ही सांगा की तुमच्या मॅ...  Offensive       TIN   \n",
       "3               भक्त आंधळे असतात मूर्खा ना काही कळत नाही  Offensive       TIN   \n",
       "4      १९६६ साली छत्रपती शिवाजी महाराज या जागतिक दर्ज...  Offensive       TIN   \n",
       "...                                                  ...        ...       ...   \n",
       "12990  पहिल्या लाटे नंतर सर्वात कमी रुग्ण\\n#कोरोना #र...       NULL      NULL   \n",
       "12991  RT @DeshRat30997789: @RavindraAmbekar जगातले स...       NULL      NULL   \n",
       "12992  Tata Tigor EV | देशातील सर्वात स्वस्त इलेक्ट्र...       NULL      NULL   \n",
       "12993  RT @PIBMumbai: पंतप्रधान आयुष्मान भारत आरोग्यव...       NULL      NULL   \n",
       "12994  @Hopeful_Addict काटकसर म्हणजे गोधड्या शिवणे.\\n...       NULL      NULL   \n",
       "\n",
       "      subtask_c  \n",
       "0           GRP  \n",
       "1           GRP  \n",
       "2           GRP  \n",
       "3           GRP  \n",
       "4           GRP  \n",
       "...         ...  \n",
       "12990      NULL  \n",
       "12991      NULL  \n",
       "12992      NULL  \n",
       "12993      NULL  \n",
       "12994      NULL  \n",
       "\n",
       "[12995 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_dataset = pd.read_csv(\"/Users/mayureshnene/Desktop/Mayuresh/Offense_Marathi/Data/Data.csv\")\n",
    "#training_dataset.dropna()\n",
    "training_dataset.fillna(\"NULL\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        राम कदम वागण्यात नाही तर बोलण्यात चुकला बीजेपी...\n",
       "1        हीच का तुमची शिवसेने चि शिकवण आपली आई म्हणजे द...\n",
       "2        हे वाचा गाढवांनो आणि हे ही सांगा की तुमच्या मॅ...\n",
       "3                 भक्त आंधळे असतात मूर्खा ना काही कळत नाही\n",
       "4        १९६६ साली छत्रपती शिवाजी महाराज या जागतिक दर्ज...\n",
       "                               ...                        \n",
       "12990    पहिल्या लाटे नंतर सर्वात कमी रुग्ण\\n#कोरोना #र...\n",
       "12991    RT @DeshRat30997789: @RavindraAmbekar जगातले स...\n",
       "12992    Tata Tigor EV | देशातील सर्वात स्वस्त इलेक्ट्र...\n",
       "12993    RT @PIBMumbai: पंतप्रधान आयुष्मान भारत आरोग्यव...\n",
       "12994    @Hopeful_Addict काटकसर म्हणजे गोधड्या शिवणे.\\n...\n",
       "Name: tweet, Length: 12995, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = training_dataset[\"tweet\"]\n",
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "level_A = training_dataset[[\"subtask_a\"]]\n",
    "# level_B = training_dataset.query(\"subtask_a == 'Offensive'\")[[\"subtask_b\"]]\n",
    "# level_C = training_dataset.query(\"subtask_b == 'TIN'\")[[\"subtask_c\"]]\n",
    "level_B_indices = training_dataset.index[training_dataset['subtask_a'] == \"Offensive\"].tolist()\n",
    "level_C_indices = training_dataset.index[training_dataset['subtask_b'] == \"TIN\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "325"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "level_B = training_dataset[\"subtask_b\"][level_B_indices]\n",
    "level_C = training_dataset[\"subtask_c\"][level_C_indices]\n",
    "training_dataset[\"subtask_c\"][level_B_indices].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['अधिक ', 'अनेक ', 'अशी ', 'असलयाचे', 'असलेल्या', 'असा', 'असून', 'असे', 'आज', 'आणि', 'आता', 'आपल्या', 'आला', 'आली', 'आले', 'आहे', 'आहेत', 'एक', 'एका', 'कमी', 'करणयात', 'करून', 'का', 'काम', 'काय', 'काही', 'किवा', 'की', 'केला', 'केली', 'केले', 'कोटी', 'गेल्या', 'घेऊन', 'जात', 'झाला', 'झाली', 'झाले', 'झालेल्या', 'टा', 'डॉ', 'तर', 'तरी', 'तसेच', 'ता', 'ती', 'तीन', 'ते', 'तो', 'त्या', 'त्याचा', 'त्याची', 'त्याच्या', 'त्याना', 'त्यानी', 'त्यामुळे', 'त्री', 'दिली', 'दोन', 'न', 'नाही', 'निर्ण्य', 'पण', 'पम', 'परयतन', 'पाटील', 'म', 'मात्र', 'माहिती', 'मी', 'मुबी', 'म्हणजे', 'म्हणाले', 'म्हणून', 'या', 'याचा', 'याची', 'याच्या', 'याना', 'यानी', 'येणार', 'येत', 'येथील', 'येथे', 'लाख', 'व', 'व्यकत', 'सर्व', 'सागित्ले', 'सुरू', 'हजार', 'हा', 'ही', 'हे', 'होणार', 'होत', 'होता', 'होती', 'होते']\n"
     ]
    }
   ],
   "source": [
    "stopwords_file = open(\"/Users/mayureshnene/Desktop/MOLD/Mold/stopwords.txt\")\n",
    "stopwords = stopwords_file.read().splitlines()\n",
    "print(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(row):\n",
    "    row = str(row)\n",
    "#     removal_list = ['URL','\\'ve','n\\'t','\\'s','\\'m','!']\n",
    "#     for element in removal_list:\n",
    "#         row = row.replace(element,'')\n",
    "    \n",
    "    row = row.replace('http\\S+|www.\\S+', '')\n",
    "    row = re.sub(\"@[A-Za-z0-9]+\",\"@USER\",row)\n",
    "    row = re.sub(\"[A-Za-z0-9]+\",\"\",row)\n",
    "    row = re.sub(\"@\",\"@USER\",row)\n",
    "    row = re.sub('[+,-,_,=,/,<,>,!,#,$,%,^,&,*,\\\",:,;,.,' ',\\t,\\r,\\n,\\',|]','',row)\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for tweet in tweets:\n",
    "#     tweet = remove_noise(str(tweet))\n",
    "iterator_map = map(clean,tweets)\n",
    "tweets = list(iterator_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "\n",
    "collective_tweets = copy.deepcopy(training_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "analyzer=unsupervised_morph.UnsupervisedMorphAnalyzer('mr')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(tweet):\n",
    "    return indic_tokenize.trivial_tokenize(tweet)\n",
    "\n",
    "def morph(tweet):\n",
    "    analyzed_tokens=analyzer.morph_analyze_document(str(tweet).split(' '))\n",
    "    return analyzed_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenize..: 100%|██████████| 12995/12995 [00:02<00:00, 4608.45it/s]\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas(desc=\"Tokenize..\")\n",
    "#all_tweets[\"tokens\"] = all_tweets['tweet'].progress_apply(tokenize)\n",
    "collective_tweets[\"tokens\"] = collective_tweets['tweet'].progress_apply(morph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = collective_tweets[\"tokens\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfid_vectorizer(vector):\n",
    "\t## Creates and stores an instance of the TfidfVectorizer class. This will be used further to extract our data as tf-idf features.\n",
    "\tvectorizer = TfidfVectorizer()\n",
    "\tuntokenized_data =[' '.join(tweet) for tweet in tqdm(vector, \"Vectorizing...\")]\n",
    "\tvectorizer = vectorizer.fit(untokenized_data)\n",
    "\tvectors = vectorizer.transform(untokenized_data).toarray()\n",
    "\treturn vectors\n",
    "\n",
    "def get_vectors(vectors, labels, keyword):\n",
    "\t'''\n",
    "\tReturns a matrix for vectors. Zips vectors and labels IF and only if length of vector list is the same as length of the labels list. \n",
    "\tElse, the function gets terminated.\n",
    "\t@param vectors These are the vectors for a given label.\n",
    "\t@param labels These are the label values for the given label.\n",
    "\t@param keyword which is the label to annotate for.\n",
    "\t'''\n",
    "\tif len(vectors) != len(labels):\n",
    "\t\tprint(\"Unmatching sizes!\")\n",
    "\t\treturn\n",
    "\t\n",
    "\t## Stores a new list to append the zipped vectors and labels into.\n",
    "\tresult = list()\n",
    "\tfor vector, label in zip(vectors, labels):\n",
    "\t\tif label == keyword:\n",
    "\t\t\tresult.append(vector)\n",
    "\treturn result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing...: 100%|██████████| 12995/12995 [00:00<00:00, 670154.19it/s]\n"
     ]
    }
   ],
   "source": [
    "vectors_level_A = tfid_vectorizer(vector)\n",
    "labels_level_a = level_A['subtask_a'].values.tolist()\n",
    "vectors_level_B = get_vectors(vectors_level_A, labels_level_a, \"Offensive\") \n",
    "\n",
    "labels_level_b = level_B.values.tolist() \n",
    "\n",
    "## Numerical Vectors C\n",
    "vectors_level_c = get_vectors(vectors_level_B, labels_level_b, \"TIN\") \n",
    "\n",
    "##Subtask C Labels\n",
    "labels_level_c = level_C.values.tolist() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training begins on Level A classification...\n"
     ]
    }
   ],
   "source": [
    "train_vectors_level_A, train_labels_level_A,= vectors_level_A[1:3097], labels_level_a[1:3097]\n",
    "test_vectors_level_A, test_labels_level_A = vectors_level_A[3097:], labels_level_a[3097:]\n",
    "## Extracting names of labels and storing them in a variable\n",
    "classNames = np.unique(test_labels_level_A)\n",
    "\n",
    "print(\"Training begins on Level A classification...\")\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "## Creating an object of SVC, MNB, SGD, MLP\n",
    "classifiersvc = SVC()\n",
    "classifiermnb = MultinomialNB()\n",
    "classifiersgd = SGDClassifier()\n",
    "classifiermlp = MLPClassifier()\n",
    "\n",
    "\n",
    "## Fit on Level A\n",
    "classifiersvc.fit(train_vectors_level_A, train_labels_level_A)\n",
    "classifiermnb.fit(train_vectors_level_A, train_labels_level_A)\n",
    "classifiersgd.fit(train_vectors_level_A, train_labels_level_A)\n",
    "classifiermlp.fit(train_vectors_level_A, train_labels_level_A)\n",
    "\n",
    "\n",
    "## Predict on Level A\n",
    "test_predictions_A_svc = classifiersvc.predict(test_vectors_level_A)\n",
    "test_predictions_A_mnb = classifiermnb.predict(test_vectors_level_A)\n",
    "test_predictions_A_sgd = classifiersgd.predict(test_vectors_level_A)\n",
    "test_predictions_A_mlp = classifiermlp.predict(test_vectors_level_A)\n",
    "\n",
    "preds_A = pd.DataFrame(columns = ['SVC_A', 'MNB_A', 'SGD_A','MLP_A'])\n",
    "label_name = ['SVC_A', 'MNB_A','SGD_A','MLP_A']\n",
    "preds = [test_predictions_A_svc, test_predictions_A_mnb, test_predictions_A_sgd, test_predictions_A_mlp]\n",
    "\n",
    "i = 0\n",
    "for label in label_name:\n",
    "    preds_A[label] = preds[i]\n",
    "    i += 1\n",
    "\n",
    "\n",
    "preds_A.to_csv(\"/Users/mayureshnene/Desktop/Mayuresh/Offense_Marathi/Experiments/Level_A_Annotated.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training begins on Level B classification...\n",
      "Training begins on Level C classification...\n"
     ]
    }
   ],
   "source": [
    "## Split into Train and Test vectors using the vectors of level A and Labels of level B with a training size of 0.75.\n",
    "train_vectors_level_B, test_vectors_level_B, train_labels_level_B, test_labels_level_B = train_test_split(vectors_level_B[:], labels_level_b[:], train_size=0.75)\n",
    "\n",
    "## Extracting names of labels and storing them in a variable\n",
    "classNames = np.unique(test_labels_level_B)\n",
    "print(\"Training begins on Level B classification...\")\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "## Creating an object of SVC, MNB, SGD, MLP\n",
    "classifiersvc = SVC()\n",
    "classifiermnb = MultinomialNB()\n",
    "classifiersgd = SGDClassifier()\n",
    "classifiermlp = MLPClassifier()\n",
    "\n",
    "## Fit on Level B\n",
    "classifiersvc.fit(train_vectors_level_B, train_labels_level_B)\n",
    "classifiermnb.fit(train_vectors_level_B, train_labels_level_B)\n",
    "classifiersgd.fit(train_vectors_level_B, train_labels_level_B)\n",
    "classifiermlp.fit(train_vectors_level_B, train_labels_level_B)\n",
    "\n",
    "## Predict on Level B\n",
    "test_predictions_B_svc = classifiersvc.predict(test_vectors_level_B)\n",
    "test_predictions_B_mnb = classifiermnb.predict(test_vectors_level_B)\n",
    "test_predictions_B_sgd = classifiersgd.predict(test_vectors_level_B)\n",
    "test_predictions_B_mlp = classifiermlp.predict(test_vectors_level_B)\n",
    "\n",
    "\n",
    "## Split into Train and Test vectors using the vectors of level A and Labels of level B with a training size of 0.75.\n",
    "train_vectors_level_C, test_vectors_level_C, train_labels_level_C, test_labels_level_C = train_test_split(vectors_level_c[:], labels_level_c[:], train_size=0.75)\n",
    "\n",
    "## Extracting names of labels and storing them in a variable\n",
    "classNames = np.unique(test_labels_level_C)\n",
    "print(\"Training begins on Level C classification...\")\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "## Creating an object of SVC, MNB, SGD, MLP\n",
    "classifiersvc = SVC()\n",
    "classifiermnb = MultinomialNB()\n",
    "classifiersgd = SGDClassifier()\n",
    "classifiermlp = MLPClassifier()\n",
    "\n",
    "## Fit on Level C\n",
    "classifiersvc.fit(train_vectors_level_C, train_labels_level_C)\n",
    "classifiermnb.fit(train_vectors_level_C, train_labels_level_C)\n",
    "classifiersgd.fit(train_vectors_level_C, train_labels_level_C)\n",
    "classifiermlp.fit(train_vectors_level_C, train_labels_level_C)\n",
    "\n",
    "\n",
    "\n",
    "## Predict on Level C\n",
    "test_predictions_C_svc = classifiersvc.predict(test_vectors_level_C)\n",
    "test_predictions_C_mnb = classifiermnb.predict(test_vectors_level_C)\n",
    "test_predictions_C_sgd = classifiersgd.predict(test_vectors_level_C)\n",
    "test_predictions_C_mlp = classifiermlp.predict(test_vectors_level_C)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_B = pd.DataFrame(columns = ['SVC_B', 'MNB_B', 'SGD_B','MLP_B'])\n",
    "label_name = ['SVC_B', 'MNB_B','SGD_B','MLP_B']\n",
    "preds = [test_predictions_B_svc, test_predictions_B_mnb, test_predictions_B_sgd, test_predictions_B_mlp]\n",
    "\n",
    "i = 0\n",
    "for label in label_name:\n",
    "    preds_B[label] = preds[i]\n",
    "    i += 1\n",
    "    \n",
    "preds_B.to_csv(\"/Users/mayureshnene/Desktop/Mayuresh/Offense_Marathi/Experiments/Level_B_Annotated.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_C = pd.DataFrame(columns = ['SVC_C', 'MNB_C', 'SGD_C','MLP_C'])\n",
    "label_name = ['SVC_C', 'MNB_C','SGD_C','MLP_C']\n",
    "preds = [test_predictions_C_svc, test_predictions_C_mnb, test_predictions_C_sgd, test_predictions_C_mlp]\n",
    "\n",
    "i = 0\n",
    "for label in label_name:\n",
    "    preds_C[label] = preds[i]\n",
    "    i += 1\n",
    "\n",
    "preds_C.to_csv(\"/Users/mayureshnene/Desktop/Mayuresh/Offense_Marathi/Experiments/Level_C_Annotated.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_df = pd.DataFrame()\n",
    "final_df = pd.concat([preds_A, preds_B, preds_C], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SVC_A</th>\n",
       "      <th>MNB_A</th>\n",
       "      <th>SGD_A</th>\n",
       "      <th>MLP_A</th>\n",
       "      <th>SVC_B</th>\n",
       "      <th>MNB_B</th>\n",
       "      <th>SGD_B</th>\n",
       "      <th>MLP_B</th>\n",
       "      <th>SVC_C</th>\n",
       "      <th>MNB_C</th>\n",
       "      <th>SGD_C</th>\n",
       "      <th>MLP_C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>not offensive</td>\n",
       "      <td>not offensive</td>\n",
       "      <td>not offensive</td>\n",
       "      <td>not offensive</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>not offensive</td>\n",
       "      <td>not offensive</td>\n",
       "      <td>not offensive</td>\n",
       "      <td>not offensive</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>not offensive</td>\n",
       "      <td>not offensive</td>\n",
       "      <td>not offensive</td>\n",
       "      <td>not offensive</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>not offensive</td>\n",
       "      <td>not offensive</td>\n",
       "      <td>not offensive</td>\n",
       "      <td>not offensive</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>not offensive</td>\n",
       "      <td>not offensive</td>\n",
       "      <td>not offensive</td>\n",
       "      <td>not offensive</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10344</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IND</td>\n",
       "      <td>IND</td>\n",
       "      <td>IND</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10345</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IND</td>\n",
       "      <td>IND</td>\n",
       "      <td>OTH</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10346</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IND</td>\n",
       "      <td>IND</td>\n",
       "      <td>GRP</td>\n",
       "      <td>GRP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10347</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IND</td>\n",
       "      <td>IND</td>\n",
       "      <td>IND</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10348</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IND</td>\n",
       "      <td>IND</td>\n",
       "      <td>IND</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10349 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               SVC_A          MNB_A          SGD_A          MLP_A SVC_B MNB_B  \\\n",
       "0      not offensive  not offensive  not offensive  not offensive   NaN   NaN   \n",
       "1      not offensive  not offensive  not offensive  not offensive   NaN   NaN   \n",
       "2      not offensive  not offensive  not offensive  not offensive   NaN   NaN   \n",
       "3      not offensive  not offensive  not offensive  not offensive   NaN   NaN   \n",
       "4      not offensive  not offensive  not offensive  not offensive   NaN   NaN   \n",
       "...              ...            ...            ...            ...   ...   ...   \n",
       "10344            NaN            NaN            NaN            NaN   NaN   NaN   \n",
       "10345            NaN            NaN            NaN            NaN   NaN   NaN   \n",
       "10346            NaN            NaN            NaN            NaN   NaN   NaN   \n",
       "10347            NaN            NaN            NaN            NaN   NaN   NaN   \n",
       "10348            NaN            NaN            NaN            NaN   NaN   NaN   \n",
       "\n",
       "      SGD_B MLP_B SVC_C MNB_C SGD_C MLP_C  \n",
       "0       NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "1       NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "2       NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "3       NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "4       NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "...     ...   ...   ...   ...   ...   ...  \n",
       "10344   NaN   NaN   IND   IND   IND   IND  \n",
       "10345   NaN   NaN   IND   IND   OTH   IND  \n",
       "10346   NaN   NaN   IND   IND   GRP   GRP  \n",
       "10347   NaN   NaN   IND   IND   IND   IND  \n",
       "10348   NaN   NaN   IND   IND   IND   IND  \n",
       "\n",
       "[10349 rows x 12 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    " #final_df.to_csv(\"/Users/mayureshnene/Desktop/Mayuresh/Offense_Marathi/Experiments/Data_annotated.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
