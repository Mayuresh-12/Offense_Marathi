{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The path to the local git repo for Indic NLP library\n",
    "INDIC_NLP_LIB_HOME=r\"/Users/mayureshnene/Desktop/indic_nlp_library\"\n",
    "\n",
    "# The path to the local git repo for Indic NLP Resources\n",
    "INDIC_NLP_RESOURCES=r\"/Users/mayureshnene/Desktop/indic_nlp_resources\"\n",
    "\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report,plot_confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from indicnlp import common\n",
    "from indicnlp import loader\n",
    "from indicnlp.tokenize import indic_tokenize\n",
    "from indicnlp.tokenize import indic_tokenize \n",
    "from indicnlp.morph import unsupervised_morph \n",
    "from indicnlp import common\n",
    "\n",
    "sys.path.append(r'{}'.format(INDIC_NLP_LIB_HOME))\n",
    "\n",
    "common.set_resources_path(INDIC_NLP_RESOURCES)\n",
    "\n",
    "loader.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>subtask_a</th>\n",
       "      <th>subtask_b</th>\n",
       "      <th>subtask_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>राम कदम वागण्यात नाही तर बोलण्यात चुकला बीजेपी...</td>\n",
       "      <td>Offensive</td>\n",
       "      <td>TIN</td>\n",
       "      <td>GRP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>हीच का तुमची शिवसेने चि शिकवण आपली आई म्हणजे द...</td>\n",
       "      <td>Offensive</td>\n",
       "      <td>TIN</td>\n",
       "      <td>GRP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>हे वाचा गाढवांनो आणि हे ही सांगा की तुमच्या मॅ...</td>\n",
       "      <td>Offensive</td>\n",
       "      <td>TIN</td>\n",
       "      <td>GRP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>भक्त आंधळे असतात मूर्खा ना काही कळत नाही</td>\n",
       "      <td>Offensive</td>\n",
       "      <td>TIN</td>\n",
       "      <td>GRP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>१९६६ साली छत्रपती शिवाजी महाराज या जागतिक दर्ज...</td>\n",
       "      <td>Offensive</td>\n",
       "      <td>TIN</td>\n",
       "      <td>GRP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1915</th>\n",
       "      <td>RT @harshadsurve999: आज महाराष्ट्रात पैसा झाला...</td>\n",
       "      <td>Offensive</td>\n",
       "      <td>TIN</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1916</th>\n",
       "      <td>RT @YadavPatil03: मी एक #शिवसैनिक माझ्या लाडक्...</td>\n",
       "      <td>Offensive</td>\n",
       "      <td>TIN</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1917</th>\n",
       "      <td>RT @PuneriSpeaks: दोन दिवसावर दिवाळी आली आहे.....</td>\n",
       "      <td>Offensive</td>\n",
       "      <td>TIN</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1918</th>\n",
       "      <td>प्रिय @StarSportsIndia\\n#मराठी भारतातील तिसरी ...</td>\n",
       "      <td>Offensive</td>\n",
       "      <td>TIN</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1919</th>\n",
       "      <td>RT @MarathiRojgar: देशात सर्वात श्रीमंत राज्य ...</td>\n",
       "      <td>Offensive</td>\n",
       "      <td>TIN</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1920 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tweet  subtask_a subtask_b  \\\n",
       "0     राम कदम वागण्यात नाही तर बोलण्यात चुकला बीजेपी...  Offensive       TIN   \n",
       "1     हीच का तुमची शिवसेने चि शिकवण आपली आई म्हणजे द...  Offensive       TIN   \n",
       "2     हे वाचा गाढवांनो आणि हे ही सांगा की तुमच्या मॅ...  Offensive       TIN   \n",
       "3              भक्त आंधळे असतात मूर्खा ना काही कळत नाही  Offensive       TIN   \n",
       "4     १९६६ साली छत्रपती शिवाजी महाराज या जागतिक दर्ज...  Offensive       TIN   \n",
       "...                                                 ...        ...       ...   \n",
       "1915  RT @harshadsurve999: आज महाराष्ट्रात पैसा झाला...  Offensive       TIN   \n",
       "1916  RT @YadavPatil03: मी एक #शिवसैनिक माझ्या लाडक्...  Offensive       TIN   \n",
       "1917  RT @PuneriSpeaks: दोन दिवसावर दिवाळी आली आहे.....  Offensive       TIN   \n",
       "1918  प्रिय @StarSportsIndia\\n#मराठी भारतातील तिसरी ...  Offensive       TIN   \n",
       "1919  RT @MarathiRojgar: देशात सर्वात श्रीमंत राज्य ...  Offensive       TIN   \n",
       "\n",
       "     subtask_c  \n",
       "0          GRP  \n",
       "1          GRP  \n",
       "2          GRP  \n",
       "3          GRP  \n",
       "4          GRP  \n",
       "...        ...  \n",
       "1915      NULL  \n",
       "1916      NULL  \n",
       "1917      NULL  \n",
       "1918      NULL  \n",
       "1919      NULL  \n",
       "\n",
       "[1920 rows x 4 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_dataset = pd.read_csv(\"/Users/mayureshnene/Desktop/Mayuresh/Offense_Marathi/Data/Pseudo_labelled_B.csv\")\n",
    "#training_dataset.dropna()\n",
    "training_dataset.fillna(\"NULL\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       राम कदम वागण्यात नाही तर बोलण्यात चुकला बीजेपी...\n",
       "1       हीच का तुमची शिवसेने चि शिकवण आपली आई म्हणजे द...\n",
       "2       हे वाचा गाढवांनो आणि हे ही सांगा की तुमच्या मॅ...\n",
       "3                भक्त आंधळे असतात मूर्खा ना काही कळत नाही\n",
       "4       १९६६ साली छत्रपती शिवाजी महाराज या जागतिक दर्ज...\n",
       "                              ...                        \n",
       "1915    RT @harshadsurve999: आज महाराष्ट्रात पैसा झाला...\n",
       "1916    RT @YadavPatil03: मी एक #शिवसैनिक माझ्या लाडक्...\n",
       "1917    RT @PuneriSpeaks: दोन दिवसावर दिवाळी आली आहे.....\n",
       "1918    प्रिय @StarSportsIndia\\n#मराठी भारतातील तिसरी ...\n",
       "1919    RT @MarathiRojgar: देशात सर्वात श्रीमंत राज्य ...\n",
       "Name: tweet, Length: 1920, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = training_dataset[\"tweet\"]\n",
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "level_A = training_dataset[[\"subtask_a\"]]\n",
    "# level_B = training_dataset.query(\"subtask_a == 'Offensive'\")[[\"subtask_b\"]]\n",
    "# level_C = training_dataset.query(\"subtask_b == 'TIN'\")[[\"subtask_c\"]]\n",
    "level_B_indices = training_dataset.index[training_dataset['subtask_a'] == \"Offensive\"].tolist()\n",
    "level_C_indices = training_dataset.index[training_dataset['subtask_b'] == \"TIN\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1920"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(level_C_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       GRP\n",
       "1       GRP\n",
       "2       GRP\n",
       "3       GRP\n",
       "4       GRP\n",
       "       ... \n",
       "1915    NaN\n",
       "1916    NaN\n",
       "1917    NaN\n",
       "1918    NaN\n",
       "1919    NaN\n",
       "Name: subtask_c, Length: 1920, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "level_B = training_dataset[\"subtask_b\"][level_B_indices]\n",
    "level_C = training_dataset[\"subtask_c\"][level_C_indices]\n",
    "level_C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['अधिक ', 'अनेक ', 'अशी ', 'असलयाचे', 'असलेल्या', 'असा', 'असून', 'असे', 'आज', 'आणि', 'आता', 'आपल्या', 'आला', 'आली', 'आले', 'आहे', 'आहेत', 'एक', 'एका', 'कमी', 'करणयात', 'करून', 'का', 'काम', 'काय', 'काही', 'किवा', 'की', 'केला', 'केली', 'केले', 'कोटी', 'गेल्या', 'घेऊन', 'जात', 'झाला', 'झाली', 'झाले', 'झालेल्या', 'टा', 'डॉ', 'तर', 'तरी', 'तसेच', 'ता', 'ती', 'तीन', 'ते', 'तो', 'त्या', 'त्याचा', 'त्याची', 'त्याच्या', 'त्याना', 'त्यानी', 'त्यामुळे', 'त्री', 'दिली', 'दोन', 'न', 'नाही', 'निर्ण्य', 'पण', 'पम', 'परयतन', 'पाटील', 'म', 'मात्र', 'माहिती', 'मी', 'मुबी', 'म्हणजे', 'म्हणाले', 'म्हणून', 'या', 'याचा', 'याची', 'याच्या', 'याना', 'यानी', 'येणार', 'येत', 'येथील', 'येथे', 'लाख', 'व', 'व्यकत', 'सर्व', 'सागित्ले', 'सुरू', 'हजार', 'हा', 'ही', 'हे', 'होणार', 'होत', 'होता', 'होती', 'होते']\n"
     ]
    }
   ],
   "source": [
    "stopwords_file = open(\"/Users/mayureshnene/Desktop/MOLD/Mold/stopwords.txt\")\n",
    "stopwords = stopwords_file.read().splitlines()\n",
    "print(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(row):\n",
    "    row = str(row)\n",
    "#     removal_list = ['URL','\\'ve','n\\'t','\\'s','\\'m','!']\n",
    "#     for element in removal_list:\n",
    "#         row = row.replace(element,'')\n",
    "    \n",
    "    row = row.replace('http\\S+|www.\\S+', '')\n",
    "    row = re.sub(\"@[A-Za-z0-9]+\",\"@USER\",row)\n",
    "    row = re.sub(\"[A-Za-z0-9]+\",\"\",row)\n",
    "    row = re.sub(\"@\",\"@USER\",row)\n",
    "    row = re.sub('[+,-,_,=,/,<,>,!,#,$,%,^,&,*,\\\",:,;,.,' ',\\t,\\r,\\n,\\',|]','',row)\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for tweet in tweets:\n",
    "#     tweet = remove_noise(str(tweet))\n",
    "iterator_map = map(clean,tweets)\n",
    "tweets = list(iterator_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "\n",
    "collective_tweets = copy.deepcopy(training_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "analyzer=unsupervised_morph.UnsupervisedMorphAnalyzer('mr')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(tweet):\n",
    "    return indic_tokenize.trivial_tokenize(tweet)\n",
    "\n",
    "def morph(tweet):\n",
    "    analyzed_tokens=analyzer.morph_analyze_document(str(tweet).split(' '))\n",
    "    return analyzed_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenize..: 100%|██████████| 1920/1920 [00:00<00:00, 4593.44it/s]\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas(desc=\"Tokenize..\")\n",
    "#all_tweets[\"tokens\"] = all_tweets['tweet'].progress_apply(tokenize)\n",
    "collective_tweets[\"tokens\"] = collective_tweets['tweet'].progress_apply(morph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = collective_tweets[\"tokens\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfid_vectorizer(vector):\n",
    "\t## Creates and stores an instance of the TfidfVectorizer class. This will be used further to extract our data as tf-idf features.\n",
    "\tvectorizer = TfidfVectorizer()\n",
    "\tuntokenized_data =[' '.join(tweet) for tweet in tqdm(vector, \"Vectorizing...\")]\n",
    "\tvectorizer = vectorizer.fit(untokenized_data)\n",
    "\tvectors = vectorizer.transform(untokenized_data).toarray()\n",
    "\treturn vectors\n",
    "\n",
    "def get_vectors(vectors, labels, keyword):\n",
    "\t'''\n",
    "\tReturns a matrix for vectors. Zips vectors and labels IF and only if length of vector list is the same as length of the labels list. \n",
    "\tElse, the function gets terminated.\n",
    "\t@param vectors These are the vectors for a given label.\n",
    "\t@param labels These are the label values for the given label.\n",
    "\t@param keyword which is the label to annotate for.\n",
    "\t'''\n",
    "\tif len(vectors) != len(labels):\n",
    "\t\tprint(\"Unmatching sizes!\")\n",
    "\t\treturn\n",
    "\t\n",
    "\t## Stores a new list to append the zipped vectors and labels into.\n",
    "\tresult = list()\n",
    "\tfor vector, label in zip(vectors, labels):\n",
    "\t\tif label == keyword:\n",
    "\t\t\tresult.append(vector)\n",
    "\treturn result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing...: 100%|██████████| 1920/1920 [00:00<00:00, 525142.72it/s]\n"
     ]
    }
   ],
   "source": [
    "vectors_level_A = tfid_vectorizer(vector)\n",
    "labels_level_a = level_A['subtask_a'].values.tolist()\n",
    "vectors_level_B = get_vectors(vectors_level_A, labels_level_a, \"Offensive\") \n",
    "\n",
    "vectors_level_B\n",
    "\n",
    "labels_level_b = level_B.values.tolist() \n",
    "\n",
    "## Numerical Vectors C\n",
    "vectors_level_c = get_vectors(vectors_level_B, labels_level_b, \"TIN\") \n",
    "\n",
    "##Subtask C Labels\n",
    "labels_level_c = level_C.values.tolist() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_vectors_level_A, train_labels_level_A,= vectors_level_A[1:3097], labels_level_a[1:3097]\n",
    "# test_vectors_level_A, test_labels_level_A = vectors_level_A[3097:], labels_level_a[3097:]\n",
    "# ## Extracting names of labels and storing them in a variable\n",
    "# classNames = np.unique(test_labels_level_A)\n",
    "\n",
    "# print(\"Training begins on Level A classification...\")\n",
    "# warnings.filterwarnings(action='ignore')\n",
    "\n",
    "# ## Creating an object of SVC, MNB, SGD, MLP\n",
    "# classifiersvc = SVC()\n",
    "# classifiermnb = MultinomialNB()\n",
    "# classifiersgd = SGDClassifier()\n",
    "# classifiermlp = MLPClassifier()\n",
    "\n",
    "\n",
    "# ## Fit on Level A\n",
    "# classifiersvc.fit(train_vectors_level_A, train_labels_level_A)\n",
    "# classifiermnb.fit(train_vectors_level_A, train_labels_level_A)\n",
    "# classifiersgd.fit(train_vectors_level_A, train_labels_level_A)\n",
    "# classifiermlp.fit(train_vectors_level_A, train_labels_level_A)\n",
    "\n",
    "\n",
    "# ## Predict on Level A\n",
    "# test_predictions_A_svc = classifiersvc.predict(test_vectors_level_A)\n",
    "# test_predictions_A_mnb = classifiermnb.predict(test_vectors_level_A)\n",
    "# test_predictions_A_sgd = classifiersgd.predict(test_vectors_level_A)\n",
    "# test_predictions_A_mlp = classifiermlp.predict(test_vectors_level_A)\n",
    "\n",
    "# preds_A = pd.DataFrame(columns = ['SVC_A', 'MNB_A', 'SGD_A','MLP_A'])\n",
    "# label_name = ['SVC_A', 'MNB_A','SGD_A','MLP_A']\n",
    "# preds = [test_predictions_A_svc, test_predictions_A_mnb, test_predictions_A_sgd, test_predictions_A_mlp]\n",
    "\n",
    "# i = 0\n",
    "# for label in label_name:\n",
    "#     preds_A[label] = preds[i]\n",
    "#     i += 1\n",
    "\n",
    "\n",
    "# preds_A.to_csv(\"/Users/mayureshnene/Desktop/Mayuresh/Offense_Marathi/Experiments/Level_A_Annotated.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training begins on Level C classification...\n"
     ]
    }
   ],
   "source": [
    "## Split into Train and Test vectors using the vectors of level A and Labels of level B with a training size of 0.75.\n",
    "\n",
    "# train_vectors_level_B, train_labels_level_B,= vectors_level_B[1:1066], labels_level_b[1:1066]\n",
    "# test_vectors_level_B, test_labels_level_B = vectors_level_B[1066:2420], labels_level_b[1066:2420]\n",
    "\n",
    "# ## Extracting names of labels and storing them in a variable\n",
    "# classNames = np.unique(test_labels_level_B)\n",
    "# print(\"Training begins on Level B classification...\")\n",
    "# warnings.filterwarnings(action='ignore')\n",
    "\n",
    "# ## Creating an object of SVC, MNB, SGD, MLP\n",
    "# classifiersvc = SVC()\n",
    "# classifiermnb = MultinomialNB()\n",
    "# classifiersgd = SGDClassifier()\n",
    "# classifiermlp = MLPClassifier()\n",
    "\n",
    "# ## Fit on Level B\n",
    "# classifiersvc.fit(train_vectors_level_B, train_labels_level_B)\n",
    "# classifiermnb.fit(train_vectors_level_B, train_labels_level_B)\n",
    "# classifiersgd.fit(train_vectors_level_B, train_labels_level_B)\n",
    "# classifiermlp.fit(train_vectors_level_B, train_labels_level_B)\n",
    "\n",
    "# ## Predict on Level B\n",
    "# test_predictions_B_svc = classifiersvc.predict(test_vectors_level_B)\n",
    "# test_predictions_B_mnb = classifiermnb.predict(test_vectors_level_B)\n",
    "# test_predictions_B_sgd = classifiersgd.predict(test_vectors_level_B)\n",
    "# test_predictions_B_mlp = classifiermlp.predict(test_vectors_level_B)\n",
    "\n",
    "\n",
    "# ## Split into Train and Test vectors using the vectors of level A and Labels of level B with a training size of 0.75.\n",
    "train_vectors_level_C, train_labels_level_C = vectors_level_c[1:739], labels_level_c[1:739]\n",
    "test_vectors_level_C, test_labels_level_C = vectors_level_c[739:], labels_level_c[739:]\n",
    "\n",
    "## Extracting names of labels and storing them in a variable\n",
    "classNames = np.unique(test_labels_level_C)\n",
    "print(\"Training begins on Level C classification...\")\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "## Creating an object of SVC, MNB, SGD, MLP\n",
    "classifiersvc = SVC()\n",
    "classifiermnb = MultinomialNB()\n",
    "classifiersgd = SGDClassifier()\n",
    "classifiermlp = MLPClassifier()\n",
    "\n",
    "## Fit on Level C\n",
    "classifiersvc.fit(train_vectors_level_C, train_labels_level_C)\n",
    "classifiermnb.fit(train_vectors_level_C, train_labels_level_C)\n",
    "classifiersgd.fit(train_vectors_level_C, train_labels_level_C)\n",
    "classifiermlp.fit(train_vectors_level_C, train_labels_level_C)\n",
    "\n",
    "\n",
    "\n",
    "## Predict on Level C\n",
    "test_predictions_C_svc = classifiersvc.predict(test_vectors_level_C)\n",
    "test_predictions_C_mnb = classifiermnb.predict(test_vectors_level_C)\n",
    "test_predictions_C_sgd = classifiersgd.predict(test_vectors_level_C)\n",
    "test_predictions_C_mlp = classifiermlp.predict(test_vectors_level_C)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_B = pd.DataFrame(columns = ['SVC_B', 'MNB_B', 'SGD_B','MLP_B'])\n",
    "label_name = ['SVC_B', 'MNB_B','SGD_B','MLP_B']\n",
    "preds = [test_predictions_B_svc, test_predictions_B_mnb, test_predictions_B_sgd, test_predictions_B_mlp]\n",
    "\n",
    "i = 0\n",
    "for label in label_name:\n",
    "    preds_B[label] = preds[i]\n",
    "    i += 1\n",
    "    \n",
    "preds_B.to_csv(\"/Users/mayureshnene/Desktop/Mayuresh/Offense_Marathi/Experiments/Level_B_Annotated.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_C = pd.DataFrame(columns = ['SVC_C', 'MNB_C', 'SGD_C','MLP_C'])\n",
    "label_name = ['SVC_C', 'MNB_C','SGD_C','MLP_C']\n",
    "preds = [test_predictions_C_svc, test_predictions_C_mnb, test_predictions_C_sgd, test_predictions_C_mlp]\n",
    "\n",
    "i = 0\n",
    "for label in label_name:\n",
    "    preds_C[label] = preds[i]\n",
    "    i += 1\n",
    "\n",
    "preds_C.to_csv(\"/Users/mayureshnene/Desktop/Mayuresh/Offense_Marathi/Experiments/Level_C_Annotated.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preds_A' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-760e73103c3b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#final_df = pd.DataFrame()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfinal_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpreds_A\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds_B\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds_C\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'preds_A' is not defined"
     ]
    }
   ],
   "source": [
    "#final_df = pd.DataFrame()\n",
    "final_df = pd.concat([preds_A, preds_B, preds_C], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #final_df.to_csv(\"/Users/mayureshnene/Desktop/Mayuresh/Offense_Marathi/Experiments/Data_annotated.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
